{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11129733,"sourceType":"datasetVersion","datasetId":6941259}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n\n\n# %% [markdown]\n# # Assignment_02 [MD SIFAT ULLAH SHEIKH, 2022-1-60-029]\n\n# %% [markdown]\n#                                         Overview Work Pipeline\n# \n# ðŸ“‹ 1. Label Conversion\n# At first I need to convert the Pascal VOC XML format, which is an XML file with bounding box coordinates in pixel values, to the YOLO format. The YOLO format is a simple .txt file with one line per object, each containing the class_id, followed by the normalized center_x, center_y, width, and height of the bounding box. \n# \n# ðŸ“‚ 2. Dataset Setup\n# Organize the dataset into a specific folder structure that YOLO models can easily work with. This involves creating a main directory (e.g., dataset/) with subfolders for images and labels, each containing train/, val/, and test/ splits. You also need a data.yaml file that specifies the paths to these folders and lists your class names.\n# \n# ðŸš€ 3. Model Training\n# You can train a **YOLOv8** or **YOLOv12** model using the command-line interface. Use key hyperparameters like epochs and batch_size, and implement early-stopping with the patience argument to prevent overfitting. This will stop the training if the model's performance on the validation set doesn't improve for a set number of epochs.\n# \n# ðŸ“Š 4. Visualization and Predictions\n# After training, the model automatically generates visualizations in the runs/ directory, showing metrics like accuracy and loss over time. To see how your model performs on new data, you can run a prediction on your test images. This will produce images with bounding boxes and class labels, letting you visually inspect the results.\n\n# %% [markdown]\n# # Import the important components\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:07:57.351816Z\",\"iopub.execute_input\":\"2025-08-13T14:07:57.352340Z\",\"iopub.status.idle\":\"2025-08-13T14:09:26.935703Z\",\"shell.execute_reply.started\":\"2025-08-13T14:07:57.352312Z\",\"shell.execute_reply\":\"2025-08-13T14:09:26.934885Z\"}}\nimport os, sys, subprocess, shlex, glob\nfrom pathlib import Path\n\n\nOFFLINE_WHEELS_DIR = Path(\"/kaggle/input/ultralytics-wheels\")  \n\ndef pip_install(cmd: str):\n    print(f\"Installing: {cmd}\")\n    rc = subprocess.call(shlex.split(cmd))\n    print(\"Return code:\", rc)\n    return rc\n\ndef ensure_ultralytics():\n    try:\n        import ultralytics\n        return True\n    except Exception:\n        pass\n\n    \n    rc = pip_install(\"pip install ultralytics==8.3.78 lxml opencv-python --quiet\")\n    if rc == 0:\n        return True\n\n    \n    if OFFLINE_WHEELS_DIR and OFFLINE_WHEELS_DIR.exists():\n        wheels = sorted(glob.glob(str(OFFLINE_WHEELS_DIR / \"*.whl\")))\n        if wheels:\n            rc = pip_install(f\"pip install --no-index --find-links {OFFLINE_WHEELS_DIR} \" +\n                             \" \".join(wheels))\n            if rc == 0:\n                return True\n\n    return False\n\nok = ensure_ultralytics()\nif not ok:\n    raise RuntimeError(\n        \"Ultralytics could not be installed. If you are offline, upload a dataset of \"\n        \"wheels (ultralytics + deps) to Kaggle and set OFFLINE_WHEELS_DIR above.\"\n    )\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:09:45.074126Z\",\"iopub.execute_input\":\"2025-08-13T14:09:45.074849Z\",\"iopub.status.idle\":\"2025-08-13T14:09:50.241654Z\",\"shell.execute_reply.started\":\"2025-08-13T14:09:45.074819Z\",\"shell.execute_reply\":\"2025-08-13T14:09:50.240866Z\"}}\n\nfrom ultralytics import YOLO\nimport xml.etree.ElementTree as ET\nimport random, shutil, math, json, yaml\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nsns.set_context(\"talk\"); sns.set_style(\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (12, 7)\n\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED)\n\n\n# %% [markdown]\n# # Dataset path setup\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:09:53.563136Z\",\"iopub.execute_input\":\"2025-08-13T14:09:53.563323Z\",\"iopub.status.idle\":\"2025-08-13T14:09:53.569221Z\",\"shell.execute_reply.started\":\"2025-08-13T14:09:53.563309Z\",\"shell.execute_reply\":\"2025-08-13T14:09:53.568474Z\"}}\n\nDATASET_ROOT = Path(\"/kaggle/input/drone-images-for-military-object-detection\")\nTRAIN_IMG_DIR = DATASET_ROOT / \"train\" / \"images\"\nTRAIN_ANN_DIR = DATASET_ROOT / \"train\" / \"annotations\"\nTEST_IMG_DIR  = DATASET_ROOT / \"test\"  / \"images\"\nTEST_ANN_DIR  = DATASET_ROOT / \"test\"  / \"annotations\" \n\nWORK_DIR   = Path(\"/kaggle/working\")\nYOLO_DATA  = WORK_DIR / \"yolo_data\"     # where we put YOLO-ready data\nYOLO_DATA.mkdir(parents=True, exist_ok=True)\n\nprint(\"Dataset exists:\", DATASET_ROOT.exists())\nprint(\"Train images dir:\", TRAIN_IMG_DIR)\nprint(\"Train ann dir   :\", TRAIN_ANN_DIR)\nprint(\"Test images dir :\", TEST_IMG_DIR)\nprint(\"Test ann dir    :\", TEST_ANN_DIR, \" (exists:\", TEST_ANN_DIR.exists(), \")\")\n\n\n# %% [markdown]\n# # EDA\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:09:56.680039Z\",\"iopub.execute_input\":\"2025-08-13T14:09:56.680694Z\",\"iopub.status.idle\":\"2025-08-13T14:10:05.256629Z\",\"shell.execute_reply.started\":\"2025-08-13T14:09:56.680672Z\",\"shell.execute_reply\":\"2025-08-13T14:10:05.255879Z\"}}\n\nIMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n\ndef read_xml_classes(xml_path: Path):\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n    names = []\n    for obj in root.findall(\"object\"):\n        name = obj.findtext(\"name\")\n        if name: names.append(name.strip())\n    return names\n\n\nxml_files = sorted(TRAIN_ANN_DIR.glob(\"*.xml\"))\nassert xml_files, f\"No XML files found under {TRAIN_ANN_DIR}\"\nclass_set = set()\nfor x in tqdm(xml_files, desc=\"Scanning classes\"):\n    for n in read_xml_classes(x):\n        class_set.add(n)\n\nclasses = sorted(class_set)\nname2id = {n:i for i,n in enumerate(classes)}\nprint(\"Classes:\", classes)\nprint(\"num_classes:\", len(classes))\n\n\ntrain_images = [p for p in TRAIN_IMG_DIR.glob(\"*\") if p.suffix.lower() in IMG_EXTS]\nsample_show = min(8, len(train_images))\nplt.figure(figsize=(16, 10))\nfor i, p in enumerate(random.sample(train_images, sample_show)):\n    img = cv2.cvtColor(cv2.imread(str(p)), cv2.COLOR_BGR2RGB)\n    plt.subplot(2, math.ceil(sample_show/2), i+1)\n    plt.imshow(img); plt.axis(\"off\"); plt.title(p.name[:28])\nplt.suptitle(\"Random training images\", y=1.02)\nplt.tight_layout(); plt.show()\n\n\n# %% [markdown]\n# # Split the train dataset\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:10:05.429162Z\",\"iopub.execute_input\":\"2025-08-13T14:10:05.429653Z\",\"iopub.status.idle\":\"2025-08-13T14:10:11.809395Z\",\"shell.execute_reply.started\":\"2025-08-13T14:10:05.429627Z\",\"shell.execute_reply\":\"2025-08-13T14:10:11.808823Z\"}}\n\ndef voc_to_yolo(size_wh, box_xyxy):\n    w, h = size_wh\n    xmin, ymin, xmax, ymax = box_xyxy\n    \n    x_c = (xmin + xmax) / 2.0 / w\n    y_c = (ymin + ymax) / 2.0 / h\n    bw  = (xmax - xmin) / w\n    bh  = (ymax - ymin) / h\n    \n    x_c = min(max(x_c, 0.0), 1.0)\n    y_c = min(max(y_c, 0.0), 1.0)\n    bw  = min(max(bw , 0.0), 1.0)\n    bh  = min(max(bh , 0.0), 1.0)\n    return x_c, y_c, bw, bh\n\ndef convert_one(xml_path: Path, out_txt: Path):\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n    W = int(root.findtext(\"size/width\"))\n    H = int(root.findtext(\"size/height\"))\n    lines = []\n    for obj in root.findall(\"object\"):\n        name = obj.findtext(\"name\").strip()\n        if name not in name2id:  \n            continue\n        cls_id = name2id[name]\n        bb = obj.find(\"bndbox\")\n        xmin = float(bb.findtext(\"xmin\")); ymin = float(bb.findtext(\"ymin\"))\n        xmax = float(bb.findtext(\"xmax\")); ymax = float(bb.findtext(\"ymax\"))\n        x,y,w,h = voc_to_yolo((W,H), (xmin,ymin,xmax,ymax))\n        lines.append(f\"{cls_id} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\")\n    out_txt.parent.mkdir(parents=True, exist_ok=True)\n    with open(out_txt, \"w\") as f:\n        f.write(\"\\n\".join(lines))\n\ndef link_copy(src: Path, dst: Path):\n    dst.parent.mkdir(parents=True, exist_ok=True)\n    try:\n        os.link(src, dst)\n    except Exception:\n        try:\n            os.symlink(src, dst)\n        except Exception:\n            shutil.copy2(src, dst)\n\n\nfor split in [\"train\", \"val\", \"test\"]:\n    (YOLO_DATA / f\"images/{split}\").mkdir(parents=True, exist_ok=True)\n    if split != \"test\":\n        (YOLO_DATA / f\"labels/{split}\").mkdir(parents=True, exist_ok=True)\n\n\nall_train_imgs = sorted([p for p in TRAIN_IMG_DIR.glob(\"*\") if p.suffix.lower() in IMG_EXTS])\nrandom.shuffle(all_train_imgs)\nVAL_RATIO = 0.15\nn_val = max(1, int(len(all_train_imgs) * VAL_RATIO))\nval_set  = set(all_train_imgs[:n_val])\ntrain_set= set(all_train_imgs[n_val:])\n\n\nfor img in tqdm(train_set, desc=\"Convert: train\"):\n    xml = TRAIN_ANN_DIR / f\"{img.stem}.xml\"\n    if not xml.exists(): \n        continue\n    link_copy(img, YOLO_DATA / f\"images/train/{img.name}\")\n    convert_one(xml, YOLO_DATA / f\"labels/train/{img.stem}.txt\")\n\nfor img in tqdm(val_set, desc=\"Convert: val\"):\n    xml = TRAIN_ANN_DIR / f\"{img.stem}.xml\"\n    if not xml.exists(): \n        continue\n    link_copy(img, YOLO_DATA / f\"images/val/{img.name}\")\n    convert_one(xml, YOLO_DATA / f\"labels/val/{img.stem}.txt\")\n\n\ntest_imgs = sorted([p for p in TEST_IMG_DIR.glob(\"*\") if p.suffix.lower() in IMG_EXTS])\nfor img in tqdm(test_imgs, desc=\"Prepare: test\"):\n    link_copy(img, YOLO_DATA / f\"images/test/{img.name}\")\n    test_xml = TEST_ANN_DIR / f\"{img.stem}.xml\"\n    if test_xml.exists():\n        convert_one(test_xml, YOLO_DATA / f\"labels/test/{img.stem}.txt\")  # only used if you run .val on test\n\nprint(\"Counts:\",\n      \"train\", len(list((YOLO_DATA/'images/train').glob('*'))),\n      \"val\",   len(list((YOLO_DATA/'images/val').glob('*'))),\n      \"test\",  len(list((YOLO_DATA/'images/test').glob('*'))))\n\n\n# %% [markdown]\n# # Level of class and EDA\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:10:23.516069Z\",\"iopub.execute_input\":\"2025-08-13T14:10:23.516603Z\",\"iopub.status.idle\":\"2025-08-13T14:10:23.762610Z\",\"shell.execute_reply.started\":\"2025-08-13T14:10:23.516576Z\",\"shell.execute_reply\":\"2025-08-13T14:10:23.761814Z\"}}\n\nDATA_YAML = YOLO_DATA / \"data.yaml\"\nyaml_dict = {\n    \"path\": str(YOLO_DATA),\n    \"train\": \"images/train\",\n    \"val\":   \"images/val\",\n    \"test\":  \"images/test\",\n    \"names\": classes\n}\nwith open(DATA_YAML, \"w\") as f:\n    yaml.safe_dump(yaml_dict, f, sort_keys=False)\n\nprint(\"Wrote:\", DATA_YAML)\nprint(yaml.safe_dump(yaml_dict, sort_keys=False))\n\n\ndef read_labels(lbl_dir: Path):\n    counts = np.zeros(len(classes), dtype=int)\n    for txt in lbl_dir.glob(\"*.txt\"):\n        with open(txt) as f:\n            for line in f:\n                line=line.strip()\n                if not line: continue\n                cls = int(line.split()[0])\n                counts[cls] += 1\n    return counts\n\ntrain_counts = read_labels(YOLO_DATA / \"labels/train\")\nplt.figure()\nplt.bar(range(len(classes)), train_counts)\nplt.xticks(range(len(classes)), classes, rotation=45, ha=\"right\")\nplt.title(\"Training label count per class\")\nplt.tight_layout(); plt.show()\n\n\n# %% [markdown]\n# # YOLOv8 Train\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:10:27.646787Z\",\"iopub.execute_input\":\"2025-08-13T14:10:27.647054Z\",\"iopub.status.idle\":\"2025-08-13T14:54:07.519470Z\",\"shell.execute_reply.started\":\"2025-08-13T14:10:27.647034Z\",\"shell.execute_reply\":\"2025-08-13T14:54:07.518505Z\"}}\n\nRUN8 = \"yolov8s_drone\"\nEPOCHS   = 100\nIMGSZ    = 640\nBATCH    = -1   \nPATIENCE = 30\n\n\ntry:\n    model8 = YOLO(\"yolov8s.pt\")\nexcept Exception as e:\n    print(\"Could not load yolov8s.pt, training from scratch:\", e)\n    model8 = YOLO(\"yolov8s.yaml\")\n\nres8 = model8.train(\n    data=str(DATA_YAML),\n    epochs=EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH,\n    device=0,\n    workers=2,\n    project=\"runs/detect\",\n    name=RUN8,\n    verbose=True,\n    \n    patience=PATIENCE,\n    \n    optimizer=\"AdamW\",\n    lr0=0.003,     \n    lrf=0.12,      \n    weight_decay=5e-4,\n    warmup_epochs=3,\n    cos_lr=True,\n    \n    degrees=5.0, translate=0.10, scale=0.9, shear=2.0,\n    fliplr=0.5, flipud=0.0,\n    mosaic=1.0, mixup=0.10,\n    erasing=0.0, copy_paste=0.0,\n    close_mosaic=10,\n    amp=True\n)\n\n\n# %% [markdown]\n# # YOLOv12\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T14:54:19.858613Z\",\"iopub.execute_input\":\"2025-08-13T14:54:19.858925Z\",\"iopub.status.idle\":\"2025-08-13T16:21:41.931135Z\",\"shell.execute_reply.started\":\"2025-08-13T14:54:19.858896Z\",\"shell.execute_reply\":\"2025-08-13T16:21:41.930299Z\"}}\n\nRUN12 = \"yolov12s_drone\"\n\n\nmodel12 = None\nerr = None\nfor candidate in [\"yolov12s.pt\", \"yolo12s.pt\"]: \n    try:\n        model12 = YOLO(candidate)\n        print(\"Loaded:\", candidate)\n        break\n    except Exception as e:\n        err = e\n        continue\n\nif model12 is None:\n    try:\n        model12 = YOLO(\"yolov12s.yaml\")\n        print(\"Loaded config: yolov12s.yaml (training from scratch)\")\n    except Exception as e2:\n        print(\"Could not load YOLOv12 weights/config automatically.\")\n        print(\"Last errors:\", err, e2)\n        raise RuntimeError(\n            \"Your Ultralytics build may not include YOLOv12. \"\n            \"Upgrade ultralytics to a version that supports YOLO12 or provide \"\n            \"local weights/config via OFFLINE_WHEELS_DIR.\"\n        )\n\nres12 = model12.train(\n    data=str(DATA_YAML),\n    epochs=EPOCHS,\n    imgsz=IMGSZ,\n    batch=BATCH,\n    device=0,\n    workers=2,\n    project=\"runs/detect\",\n    name=RUN12,\n    verbose=True,\n    patience=PATIENCE,\n    optimizer=\"AdamW\",\n    lr0=0.003, lrf=0.12, weight_decay=5e-4, warmup_epochs=3, cos_lr=True,\n    degrees=5.0, translate=0.10, scale=0.9, shear=2.0,\n    fliplr=0.5, flipud=0.0,\n    mosaic=1.0, mixup=0.10, erasing=0.0, copy_paste=0.0,\n    close_mosaic=10,\n    amp=True\n)\n\n\n# %% [markdown]\n# # Plot of results\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T16:40:53.827088Z\",\"iopub.execute_input\":\"2025-08-13T16:40:53.827928Z\",\"iopub.status.idle\":\"2025-08-13T16:40:53.916464Z\",\"shell.execute_reply.started\":\"2025-08-13T16:40:53.827895Z\",\"shell.execute_reply\":\"2025-08-13T16:40:53.915884Z\"}}\n\nfrom IPython.display import Image, display\ndef show_run(run_name: str):\n    rd = Path(\"runs/detect\") / run_name\n    print(\"Run dir:\", rd)\n    for f in [\"results.png\",\"confusion_matrix.png\",\"PR_curve.png\",\n              \"F1_curve.png\",\"P_curve.png\",\"R_curve.png\"]:\n        p = rd / f\n        if p.exists():\n            display(Image(filename=str(p)))\n\nshow_run(RUN8)\nshow_run(RUN12)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T16:41:05.929658Z\",\"iopub.execute_input\":\"2025-08-13T16:41:05.929920Z\",\"iopub.status.idle\":\"2025-08-13T16:41:34.554743Z\",\"shell.execute_reply.started\":\"2025-08-13T16:41:05.929903Z\",\"shell.execute_reply\":\"2025-08-13T16:41:34.554011Z\"}}\n\nbest8  = YOLO(str(Path(\"runs/detect\") / RUN8  / \"weights\" / \"best.pt\"))\nbest12 = YOLO(str(Path(\"runs/detect\") / RUN12 / \"weights\" / \"best.pt\"))\n\nprint(\"YOLOv8 Validation:\")\nm8 = best8.val(data=str(DATA_YAML), imgsz=IMGSZ, device=0, plots=True)\n\nprint(\"YOLOv12 Validation:\")\nm12 = best12.val(data=str(DATA_YAML), imgsz=IMGSZ, device=0, plots=True)\n\n\ntest_lbl_dir = YOLO_DATA / \"labels/test\"\nif test_lbl_dir.exists() and any(test_lbl_dir.glob(\"*.txt\")):\n    print(\"\\nEvaluating on TEST split (labels found):\")\n    data_test_yaml = YOLO_DATA / \"data_test.yaml\"\n    with open(data_test_yaml, \"w\") as f:\n        yaml.safe_dump({\n            \"path\": str(YOLO_DATA),\n            \"train\": \"images/train\",\n            \"val\":   \"images/val\",\n            \"test\":  \"images/test\",\n            \"names\": classes\n        }, f, sort_keys=False)\n    _ = best8.val(data=str(data_test_yaml), split=\"test\", imgsz=IMGSZ, device=0)\n    _ = best12.val(data=str(data_test_yaml), split=\"test\", imgsz=IMGSZ, device=0)\nelse:\n    print(\"No test labels found; skipping test evaluation (we'll do predictions next).\")\n\n\n# %% [markdown]\n# # Save the models\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-08-13T16:42:56.581575Z\",\"iopub.execute_input\":\"2025-08-13T16:42:56.582288Z\",\"iopub.status.idle\":\"2025-08-13T16:42:56.586485Z\",\"shell.execute_reply.started\":\"2025-08-13T16:42:56.582263Z\",\"shell.execute_reply\":\"2025-08-13T16:42:56.585655Z\"}}\nbest_model_path = \"/kaggle/working/results_v8/drone_yolov8/weights/best.pt\"\nprint(\"Best model saved at:\", best_model_path)\n\n\n# %% [markdown]\n# # Thank You.","metadata":{"_uuid":"d8319e5f-4678-4713-a56b-aa3f785e5ab0","_cell_guid":"5d18521f-5bc1-4034-834c-b05a7b89c149","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}